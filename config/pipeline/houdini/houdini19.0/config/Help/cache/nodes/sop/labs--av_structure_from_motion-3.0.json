{"type": "root", "attrs": {"type": "node", "context": "sop", "internal": "labs::av_structure_from_motion::3.0", "icon": "alicevision.png", "tags": "sidefxlabs,  photogrammetry", "version": "3.0", "namespace": "labs"}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Labs AV Structure from Motions"], "extent": [0, 35]}, {"type": "summary", "indent": 0, "text": [" Detects 3D points with position and orientation and calibrate the cameras accordingly using Alicevision. "], "extent": [168, 282]}, {"type": "para", "indent": 0, "text": ["The objective of this step is to understand the geometric relationship behind all the observations provided by the input images, and infer the rigid scene structure (3D points) with the pose (position and orientation) and internal calibration of all cameras. The output of this node will be a point cloud."], "extent": [282, 589]}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [589, 601], "body": [{"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Main"], "extent": [601, 616], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Cook"], "extent": [616, 626], "body": [{"type": "para", "indent": 8, "text": ["Start the cooking process for this step."], "extent": [626, 675]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Manual Mode"], "extent": [675, 692], "body": [{"type": "para", "indent": 8, "text": ["This toggle controls if the node should automatically recook if any dependencies have changed."], "extent": [692, 795]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Log"], "extent": [795, 808], "body": [{"type": "para", "indent": 8, "text": ["This toggle controls if the status of the current node should be printed to the console. This is useful for getting a quick overview of the progress."], "extent": [808, 966]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Structure From Motion"], "extent": [966, 998], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Describer Types"], "extent": [998, 1019], "body": [{"type": "para", "indent": 8, "text": ["Describer types used to describe an image."], "extent": [1019, 1070]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Localizer Estimator"], "extent": [1070, 1095], "body": [{"type": "para", "indent": 8, "text": ["Estimator type used to localize cameras (acransac, ransac, lsmeds, loransac, maxconsensus)."], "extent": [1095, 1195]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Num of Matches"], "extent": [1195, 1219], "body": [{"type": "para", "indent": 8, "text": ["Maximum number of matches per image pair (and per feature type).\n        This can be useful to have a quick reconstruction overview. 0 means no limit."], "extent": [1219, 1378]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Inter File Extension"], "extent": [1378, 1404], "body": [{"type": "para", "indent": 8, "text": ["Extension of the intermediate file export."], "extent": [1404, 1455]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Image Matching"], "extent": [1455, 1480], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Min Number of Images"], "extent": [1480, 1506], "body": [{"type": "para", "indent": 8, "text": ["Minimal number of images to use the vocabulary tree. If we have less features than this threshold, we will compute all matching combinations."], "extent": [1506, 1656]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Descriptors"], "extent": [1656, 1677], "body": [{"type": "para", "indent": 8, "text": ["Limit the number of descriptors you load per image. Zero means no limit."], "extent": [1677, 1758]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Number of Matches"], "extent": [1758, 1781], "body": [{"type": "para", "indent": 8, "text": ["The number of matches to retrieve for each image (If 0 it will retrieve all the matches)."], "extent": [1781, 1879]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Lock Scene Previously Reconstructed"], "extent": [1879, 1920], "body": [{"type": "para", "indent": 8, "text": ["This option is useful for SfM augmentation. Lock previously reconstructed poses and intrinsics."], "extent": [1920, 2024]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Local Bundle Adjustment"], "extent": [2024, 2053], "body": [{"type": "para", "indent": 8, "text": ["It reduces the reconstruction time, especially for large datasets (500+ images), by avoiding computation of the Bundle Adjustment on areas that are not changing."], "extent": [2053, 2223]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Only Inputfolder Matches"], "extent": [2223, 2257], "body": [{"type": "para", "indent": 8, "text": ["Use only matches from the input matchesFolder parameter. Matches folders previously added to the SfMData file will be ignored."], "extent": [2257, 2392]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Force Lock of All Intrinsic Camera Parameters"], "extent": [2392, 2443], "body": [{"type": "para", "indent": 8, "text": ["Force to keep constant all the intrinsics parameters of the cameras (focal length, principal point, distortion if any) during the reconstruction. This may be helpful if the input cameras are already fully calibrated."], "extent": [2443, 2668]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Rig Constraint"], "extent": [2668, 2692], "body": [{"type": "para", "indent": 8, "text": ["Enable/Disable rig constraint."], "extent": [2692, 2731]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Localizer Max Ransac Iterations"], "extent": [2731, 2768], "body": [{"type": "para", "indent": 8, "text": ["Maximum number of iterations allowed in ransac step."], "extent": [2768, 2829]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["LocalBA Graph Distance"], "extent": [2829, 2857], "body": [{"type": "para", "indent": 8, "text": ["Graph-distance limit to define the Active region in the Local Bundle Adjustment strategy."], "extent": [2857, 2955]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Input Track Length"], "extent": [2955, 2983], "body": [{"type": "para", "indent": 8, "text": ["Minimum track length in input of SfM."], "extent": [2983, 3029]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Observation for Triangulation"], "extent": [3029, 3068], "body": [{"type": "para", "indent": 8, "text": ["Minimum number of observations to triangulate a point. Set it to 3 (or more) reduces drastically the noise in the point cloud, but the number of final poses is a little bit reduced (from 1.5% to 11% on the tested datasets)."], "extent": [3068, 3300]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Angle for Triangulation"], "extent": [3300, 3333], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle for triangulation."], "extent": [3333, 3374]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Localizer Max Ransac Error"], "extent": [3374, 3406], "body": [{"type": "para", "indent": 8, "text": ["Maximum error (in pixels) allowed for camera localization (resectioning). If set to 0, it will select a threshold according to the localizer estimator used (if ACRansac, it will analyze the input data to select the optimal value)."], "extent": [3406, 3645]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Angle for Landmark"], "extent": [3645, 3673], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle for landmark."], "extent": [3673, 3709]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Reprojection Error"], "extent": [3709, 3737], "body": [{"type": "para", "indent": 8, "text": ["Maximum reprojection error."], "extent": [3737, 3773]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Angle Initial Pair"], "extent": [3773, 3801], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle for the initial pair."], "extent": [3801, 3845]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Angle Initial Pair"], "extent": [3845, 3873], "body": [{"type": "para", "indent": 8, "text": ["Maximum angle for the initial pair."], "extent": [3873, 3917]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Prepare Dense Scene"], "extent": [3917, 3947], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Output File Type"], "extent": [3947, 3969], "body": [{"type": "para", "indent": 8, "text": ["Output file type for the undistorted images."], "extent": [3969, 4022]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Save Metadata"], "extent": [4022, 4041], "body": [{"type": "para", "indent": 8, "text": ["Save projections and intrinsics information in images metadata (only for .exr images)."], "extent": [4041, 4136]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Save Matrices Text Files"], "extent": [4136, 4166], "body": [{"type": "para", "indent": 8, "text": ["Save projections and intrinsics information in text files."], "extent": [4166, 4233]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Correct images exposure"], "extent": [4233, 4262], "body": [{"type": "para", "indent": 8, "text": ["Apply a correction on images Exposure Value."], "extent": [4262, 4316]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}], "text": "Parameters"}, {"level": 1, "id": "outputs", "container": true, "type": "outputs_section", "indent": 0, "role": "section", "extent": [4316, 4325], "body": [{"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["AV Depth Map"], "extent": [4325, 4339], "body": [{"type": "para", "indent": 4, "text": ["This plugs into AV Depth Map"], "extent": [4339, 4372]}], "container": true}, {"type": "dt", "indent": 0, "text": ["Pointcloud"], "extent": [4372, 4384], "body": [{"type": "para", "indent": 4, "text": ["This is the pointcloud generated by the Prepare Dense Scene step."], "extent": [4384, 4453]}], "container": true}], "container": true}], "text": "Outputs"}], "title": ["Labs AV Structure from Motions"], "summary": [" Detects 3D points with position and orientation and calibrate the cameras accordingly using Alicevision. "]}